# ============================================================================
# LLM Lawyer - GPU/Optimized Requirements (Optional)
# ============================================================================
# Install these AFTER installing base requirements.txt
# These are optional optimizations for GPU training
# ============================================================================

# Flash Attention for faster training (requires CUDA 11.8+)
# Install with: pip install flash-attn --no-build-isolation
# Or specific version:
flash-attn==2.5.6

# PyTorch with CUDA (choose based on your CUDA version)
# For CUDA 11.8:
# torch==2.2.0+cu118
# torchvision==0.17.0+cu118
# torchaudio==2.2.0+cu118

# For CUDA 12.1:
# torch==2.2.0+cu121
# torchvision==0.17.0+cu121
# torchaudio==2.2.0+cu121

# Note: Install PyTorch from pytorch.org based on your system
# Visit: https://pytorch.org/get-started/locally/

